{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Benford's Law in Image Forgey Detection\n",
    "\n",
    "This notebook demonstrates the application of Benford's Law in detecting forged images.\n",
    "\n",
    "Benford's Law states that in many naturally occurring collections of numbers, the distribution of the first digits follows the logarithmic distribution:\n",
    "\n",
    "$$F_a = \\log_{10}\\frac{a + 1}{a}$$\n",
    "\n",
    "where $a$ is the first digit and $F_a$ is the probability of the first digit being $a$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Benford's Law distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 11})\n",
    "\n",
    "# Benford's Law distribution\n",
    "DIGITS = np.arange(1, 10)\n",
    "BENFORD = np.log10(1 + 1 / DIGITS)\n",
    "\n",
    "# Plot\n",
    "plt.margins(0, tight=True)\n",
    "plt.plot(DIGITS, BENFORD, \"s-\", color=\"black\", clip_on=False, markerfacecolor=\"none\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.title(\"Benford's Law Distribution\")\n",
    "plt.xlabel(\"First Digit\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.ylim(0.001, 0.35)\n",
    "plt.tick_params(direction=\"in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this notebook, we will be using a dataset that closely matches the one stated in the paper \"Benford's law applied to digital forensic analysis\" by Fernandes et al (2023):\n",
    "\n",
    "| Name                            |   Fake   |   Real   |\n",
    "| ------------------------------- | :------: | :------: |\n",
    "| Columbia Image Splicing Dataset |   180    |   180    |\n",
    "| COVERAGE dataset                |   100    |   100    |\n",
    "| CelebA-HQ dataset               |    -     |   8600   |\n",
    "| This person does not exist      |   120    |    -     |\n",
    "| 100K-Faces-HQ Datset            |   8600   |    -     |\n",
    "| Flickr-Faces-HQ Dataset         |          |   120    |\n",
    "|                                 |          |          |\n",
    "| **Total**                       | **9000** | **9000** |\n",
    "\n",
    "However, due to the paper's lack of clear details on the methodology (for example, the CelebA-HQ dataset consists of 30,000 images, but only 8,600 were used), the dataset recreated is done to the best of my abilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake files: 9000, Real files: 9000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_fake = [\"../../dataset/fake/100k\"]\n",
    "dir_real = [\"../../dataset/real/celeba-hq\"]\n",
    "\n",
    "\n",
    "def gather_files(dirs: list[str]) -> list[str]:\n",
    "    \"\"\"Collect all file paths, filter invalid files and return a list of valid file paths.\"\"\"\n",
    "    return [\n",
    "        os.path.join(subdir, file)\n",
    "        for dir in dirs\n",
    "        for subdir, _, files in os.walk(dir)\n",
    "        for file in files\n",
    "        if os.path.isfile(os.path.join(subdir, file))\n",
    "    ]\n",
    "\n",
    "\n",
    "fake_files = gather_files(dir_fake)\n",
    "real_files = gather_files(dir_real)\n",
    "\n",
    "print(f\"Fake files: {len(fake_files)}, Real files: {len(real_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transform (DFT)\n",
    "\n",
    "The methodology is as follows:\n",
    "\n",
    "1. Read the image and convert it to grayscale.\n",
    "2. Apply the Discrete Fourier Transform (DFT) to the image to obtain a 2D Power Spectrum.\n",
    "3. Azimuthally Average the Power Spectrum to obtain a 1D Power Spectrum.\n",
    "4. Interpolate the 1D Power Spectrum to obtain a 1D Power Spectrum with fixed number of features.\n",
    "5. Use hypothesis testing to determine if the image is real or fake wrt Benford's Law.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import cv2\n",
    "import scipy.interpolate\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def azimuthalAverage(magnitude_spectrum: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculate the azimuthally averaged 1D power spectrum of an image.\"\"\"\n",
    "    height, width = magnitude_spectrum.shape\n",
    "\n",
    "    # Calculate the indices from the image\n",
    "    y, x = np.indices([height, width])\n",
    "\n",
    "    center_y, center_x = (height - 1) / 2, (width - 1) / 2\n",
    "\n",
    "    r = np.hypot(y - center_y, x - center_x)\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int = r.astype(int)\n",
    "\n",
    "    # Calculate the mean for each radius bin\n",
    "    tbin = np.bincount(r_int.ravel(), magnitude_spectrum.ravel())\n",
    "    nr = np.bincount(r_int.ravel())\n",
    "\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "\n",
    "def fft(\n",
    "    filename: str,\n",
    "    features: int = 1000,\n",
    "    crop: bool = True,\n",
    ") -> list[float]:\n",
    "    \"\"\"Perform FFT on an image and return the azimuthally averaged 1D power spectrum.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    height, width = img.shape\n",
    "\n",
    "    if crop:\n",
    "        y = height // 3\n",
    "        x = width // 3\n",
    "        img = img[y:-y, x:-x]\n",
    "\n",
    "    # do FFT and shift zero frequency component to center\n",
    "    frequencies = np.fft.fftshift(np.fft.fft2(img))\n",
    "\n",
    "    # Calculate the magnitude of the spectrum\n",
    "    magnitude_spectrum = np.abs(frequencies)\n",
    "\n",
    "    # Calculate the azimuthally averaged 1D power spectrum\n",
    "    psd1D = azimuthalAverage(magnitude_spectrum)\n",
    "\n",
    "    # Interpolate the 1D power spectrum to a fixed number of features\n",
    "    points = np.linspace(0, features, num=psd1D.size)  # coordinates of points in psd1D\n",
    "    xi = np.linspace(0, features, num=features)  # coordinates for interpolation\n",
    "\n",
    "    interpolated = scipy.interpolate.griddata(points, psd1D, xi, method=\"cubic\")\n",
    "\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "def multithread_fft(filenames: list[str], **kwargs) -> list[list[float]]:\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(partial(fft, **kwargs), filenames),\n",
    "                total=len(filenames),\n",
    "                desc=\"Performing Feature Extraction\",\n",
    "            )\n",
    "        )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Feature Extraction: 100%|██████████| 9000/9000 [00:31<00:00, 288.47it/s]\n",
      "Performing Feature Extraction: 100%|██████████| 9000/9000 [00:27<00:00, 328.86it/s]\n"
     ]
    }
   ],
   "source": [
    "psd1D_total_fake = multithread_fft(fake_files)\n",
    "psd1D_total_real = multithread_fft(real_files)\n",
    "\n",
    "# Remove None results if any files failed to process\n",
    "psd1D_total_fake = [result for result in psd1D_total_fake if result is not None]\n",
    "psd1D_total_real = [result for result in psd1D_total_real if result is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_total_fake = np.full(len(psd1D_total_fake), True)\n",
    "label_total_real = np.full(len(psd1D_total_real), False)\n",
    "\n",
    "features = psd1D_total_fake + psd1D_total_real\n",
    "labels = np.concatenate((label_total_fake, label_total_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Digits Extraction\n",
    "\n",
    "To prepare our dataset for analysis, we will extract the first digits of the DFT coefficients of the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting First Digits: 100%|██████████| 18000/18000 [00:06<00:00, 2859.42it/s]\n",
      "Counting First Digits: 100%|██████████| 18000/18000 [00:02<00:00, 8691.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_first_digit(value: float) -> int:\n",
    "    \"\"\"Get the first digit of a value.\"\"\"\n",
    "    return int(str(abs(value))[0])\n",
    "\n",
    "\n",
    "def get_first_digit_array(array: list[float]) -> list[int]:\n",
    "    \"\"\"Get the first digit of each value in an array.\"\"\"\n",
    "    return [get_first_digit(value) for value in array]\n",
    "\n",
    "\n",
    "def get_digit_counts(array: list[int]) -> list[int]:\n",
    "    \"\"\"Count the occurrences of each digit in an array.\"\"\"\n",
    "    return [array.count(digit) for digit in DIGITS]\n",
    "\n",
    "\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    first_digits = list(\n",
    "        tqdm(\n",
    "            pool.imap(get_first_digit_array, features),\n",
    "            total=len(features),\n",
    "            desc=\"Getting First Digits\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    first_digits_counts = list(\n",
    "        tqdm(\n",
    "            pool.imap(get_digit_counts, first_digits),\n",
    "            total=len(first_digits),\n",
    "            desc=\"Counting First Digits\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Here, we will do hypothesis testing to determine whether a picture is considered fake or not. We will use the Pearson's Correlation Coefficient of the distribution of the image's first digits count with respect to the Benford's Law.\n",
    "\n",
    "If the absolute value of the Pearson's Correlation Coefficient $\\rho$ is close to 1, then the first digit distribution follows Benford's Law, and we can consider the image as real. Otherwise, if the absolute value of the Pearson's Correlation Coefficient is not equal to 1, then the first digit distribution does not follow Benford's Law, and we can consider the image as fake.\n",
    "\n",
    "$$H_0: \\rho = 1 \\text{(Real Image)}$$\n",
    "$$H_1: \\rho \\neq 1 \\text{(Fake Image)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# H0: The first digits distribution follows Benford's Law\n",
    "# H1: The first digits distribution does not follow Benford's Law\n",
    "\n",
    "# Fail to reject H0 when absolute value of correlation coefficient is close to 1\n",
    "# Reject H0 when absolute value of correlation coefficient is below 1 - alpha\n",
    "\n",
    "# H0 is equal to false, H1 is equal to true\n",
    "# So return true when absolute value of correlation coefficient is below 1 - alpha\n",
    "\n",
    "# (I had to write the above to deconfuse myself)\n",
    "\n",
    "\n",
    "def test_results(\n",
    "    threshold: int,\n",
    "    first_digits_counts: list[list[int]] = first_digits_counts,\n",
    ") -> dict:\n",
    "    \"\"\"Test the goodness of fit for each feature and return the confusion matrix and performance metrics.\"\"\"\n",
    "    goodness_of_fit = [\n",
    "        stats.pearsonr(first_digits_count, BENFORD)\n",
    "        for first_digits_count in first_digits_counts\n",
    "    ]\n",
    "\n",
    "    # calculate True Positive, False Positive, True Negative, False Negative\n",
    "    results = [abs(coeff) < threshold for coeff, _ in goodness_of_fit]\n",
    "\n",
    "    # label for fake is 0/False, real is 1/True\n",
    "    TN, FP, FN, TP = metrics.confusion_matrix(labels, results).ravel()\n",
    "\n",
    "    return {\n",
    "        \"TN\": TN,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"TP\": TP,\n",
    "        \"Precision\": metrics.precision_score(labels, results),\n",
    "        \"Recall\": metrics.recall_score(labels, results),\n",
    "        \"F1\": metrics.f1_score(labels, results),\n",
    "        \"Accuracy\": metrics.accuracy_score(labels, results),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Threshold</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>1</td>\n",
       "      <td>8999</td>\n",
       "      <td>0</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.500028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.500056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.990</th>\n",
       "      <td>191</td>\n",
       "      <td>8809</td>\n",
       "      <td>12</td>\n",
       "      <td>8988</td>\n",
       "      <td>0.505029</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.670821</td>\n",
       "      <td>0.509944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.950</th>\n",
       "      <td>3888</td>\n",
       "      <td>5112</td>\n",
       "      <td>93</td>\n",
       "      <td>8907</td>\n",
       "      <td>0.635352</td>\n",
       "      <td>0.989667</td>\n",
       "      <td>0.773882</td>\n",
       "      <td>0.710833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>7091</td>\n",
       "      <td>1909</td>\n",
       "      <td>237</td>\n",
       "      <td>8763</td>\n",
       "      <td>0.821121</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.890911</td>\n",
       "      <td>0.880778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.800</th>\n",
       "      <td>8581</td>\n",
       "      <td>419</td>\n",
       "      <td>608</td>\n",
       "      <td>8392</td>\n",
       "      <td>0.952446</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.942339</td>\n",
       "      <td>0.942944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.750</th>\n",
       "      <td>8806</td>\n",
       "      <td>194</td>\n",
       "      <td>935</td>\n",
       "      <td>8065</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>0.896111</td>\n",
       "      <td>0.934585</td>\n",
       "      <td>0.937278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Threshold    TN    FP   FN    TP  Precision    Recall        F1  Accuracy\n",
       "0.999         1  8999    0  9000   0.500028  1.000000  0.666691  0.500056\n",
       "0.990       191  8809   12  8988   0.505029  0.998667  0.670821  0.509944\n",
       "0.950      3888  5112   93  8907   0.635352  0.989667  0.773882  0.710833\n",
       "0.900      7091  1909  237  8763   0.821121  0.973667  0.890911  0.880778\n",
       "0.800      8581   419  608  8392   0.952446  0.932444  0.942339  0.942944\n",
       "0.750      8806   194  935  8065   0.976510  0.896111  0.934585  0.937278"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the table using pandas Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = [0.999, 0.99, 0.95, 0.9, 0.8, 0.75]\n",
    "\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    results = pool.map(test_results, THRESHOLD)\n",
    "\n",
    "df = pd.DataFrame.from_records(results, index=THRESHOLD)\n",
    "df.columns.name = \"Threshold\"\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
